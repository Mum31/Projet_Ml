# ğŸ§  Machine Learning Interactive Dashboard

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Made with Love](https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg)](https://github.com/yourusername)

> **Une application web interactive pour explorer et comparer les algorithmes fondamentaux du Machine Learning : KNN, K-Means et Classification Ascendante HiÃ©rarchique (CAH)**

![Dashboard Preview](assets/dashboard_preview.png)

## âœ¨ FonctionnalitÃ©s

### ğŸ¯ Trois Algorithmes ImplÃ©mentÃ©s from Scratch
- **KNN (K-Nearest Neighbors)** - Classification supervisÃ©e
- **K-Means** - Clustering par partitionnement
- **CAH (Hierarchical Clustering)** - Clustering hiÃ©rarchique

### ğŸ¨ Interface Moderne
- Design moderne avec gradients et glassmorphism
- Animations fluides et transitions CSS
- Interface responsive et intuitive
- Visualisations matplotlib enrichies

### ğŸ“Š Outils d'Analyse
- **GÃ©nÃ©ration de donnÃ©es synthÃ©tiques** personnalisable
- **MÃ©thode du coude** pour K-Means
- **Dendrogrammes interactifs** pour la CAH
- **MÃ©triques de performance** en temps rÃ©el
- **Comparaison cÃ´te Ã  cÃ´te** des algorithmes

### ğŸ”§ ParamÃ¨tres Ajustables
- Nombre d'Ã©chantillons
- Niveau de bruit
- Nombre de clusters
- ParamÃ¨tres spÃ©cifiques Ã  chaque algorithme
- Seeds alÃ©atoires pour la reproductibilitÃ©

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
```bash
Python 3.8+
pip
```

### Installation

1. **Clonez le repository**
```bash
git clone https://github.com/yourusername/ml-interactive-dashboard.git
cd ml-interactive-dashboard
```

2. **CrÃ©ez un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

3. **Installez les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Lancez l'application**
```bash
streamlit run streamlit_app.py
```

5. **Ouvrez votre navigateur**
```
L'application s'ouvre automatiquement sur http://localhost:8501
```

## ğŸ“ Structure du Projet

```
ml-interactive-dashboard/
â”‚
â”œâ”€â”€ streamlit_app.py           # Application principale Streamlit
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md                  # Documentation
â”‚
â”œâ”€â”€ algorithms/                # ImplÃ©mentations des algorithmes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ knn.py                # K-Nearest Neighbors
â”‚   â”œâ”€â”€ kmeans.py             # K-Means Clustering
â”‚   â””â”€â”€ hierarchical.py       # Hierarchical Clustering
â”‚
â”œâ”€â”€ assets/                    # Ressources (images, etc.)
â”‚   â””â”€â”€ dashboard_preview.png
â”‚
â””â”€â”€ tests/                     # Tests unitaires
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_knn.py
    â”œâ”€â”€ test_kmeans.py
    â””â”€â”€ test_hierarchical.py
```

## ğŸ“ Algorithmes DÃ©taillÃ©s

### ğŸ” K-Nearest Neighbors (KNN)
**Classification supervisÃ©e basÃ©e sur la proximitÃ©**

```python
from algorithms.knn import KNN

# Initialisation
knn = KNN(k=5)

# EntraÃ®nement
knn.fit(X_train, y_train)

# PrÃ©diction
predictions = knn.predict(X_test)
```

**ComplexitÃ© :** O(nÂ·d) oÃ¹ n = nombre d'Ã©chantillons, d = dimensions

**Avantages :**
- âœ… Simple et intuitif
- âœ… Pas de phase d'entraÃ®nement
- âœ… Adaptatif aux nouvelles donnÃ©es

**Limitations :**
- âš ï¸ Lent pour la prÃ©diction
- âš ï¸ Sensible au choix de k
- âš ï¸ Curse of dimensionality

### ğŸ¯ K-Means Clustering
**Clustering non-supervisÃ© par partitionnement**

```python
from algorithms.kmeans import KMeans

# Initialisation
kmeans = KMeans(k=3, max_iters=100)

# Clustering
labels = kmeans.fit(X)

# CentroÃ¯des
centroids = kmeans.centroids
```

**ComplexitÃ© :** O(nÂ·dÂ·kÂ·i) oÃ¹ i = nombre d'itÃ©rations

**Avantages :**
- âœ… Rapide et Ã©volutif
- âœ… Garantie de convergence
- âœ… Efficace pour grands datasets

**Limitations :**
- âš ï¸ NÃ©cessite de choisir k
- âš ï¸ Sensible Ã  l'initialisation
- âš ï¸ Suppose des clusters sphÃ©riques

### ğŸŒ³ Classification Ascendante HiÃ©rarchique (CAH)
**Clustering hiÃ©rarchique bottom-up**

```python
from algorithms.hierarchical import HierarchicalClustering

# Initialisation
cah = HierarchicalClustering(method='ward')

# Construction de l'arbre
linkage_matrix = cah.fit(X)

# Extraction des clusters
labels = cah.get_clusters(n_clusters=3)
```

**ComplexitÃ© :** O(nÂ³) en espace et temps

**Avantages :**
- âœ… Visualisation hiÃ©rarchique (dendrogramme)
- âœ… Pas besoin de k Ã  l'avance
- âœ… Capture des structures complexes

**Limitations :**
- âš ï¸ TrÃ¨s coÃ»teux computationnellement
- âš ï¸ Sensible au bruit
- âš ï¸ Non adaptÃ© aux grands datasets

## ğŸ“Š Captures d'Ã‰cran

### Page d'Accueil
![Home](assets/home.png)

### KNN - Classification
![KNN Demo](assets/knn_demo.png)

### K-Means - MÃ©thode du Coude
![K-Means Elbow](assets/kmeans_elbow.png)

### CAH - Dendrogramme
![CAH Dendrogram](assets/cah_dendrogram.png)

### Comparaison Globale
![Comparison](assets/comparison.png)

## ğŸ› ï¸ Technologies UtilisÃ©es

- **[Streamlit](https://streamlit.io/)** - Framework web interactif
- **[NumPy](https://numpy.org/)** - Calcul scientifique
- **[Matplotlib](https://matplotlib.org/)** - Visualisations
- **[Seaborn](https://seaborn.pydata.org/)** - Visualisations statistiques
- **[Scikit-learn](https://scikit-learn.org/)** - MÃ©triques et datasets
- **[SciPy](https://scipy.org/)** - Calculs scientifiques avancÃ©s
- **[Pandas](https://pandas.pydata.org/)** - Manipulation de donnÃ©es

## ğŸ“ˆ MÃ©triques ImplÃ©mentÃ©es

### Classification (KNN)
- **Accuracy** - Taux de prÃ©dictions correctes
- **Precision, Recall, F1-Score** - MÃ©triques dÃ©taillÃ©es par classe
- **Classification Report** - Rapport complet

### Clustering (K-Means, CAH)
- **Silhouette Score** - QualitÃ© de la sÃ©paration des clusters
- **Inertie** - Variance intra-cluster (K-Means)
- **MÃ©thode du coude** - DÃ©termination du k optimal

## ğŸ¯ Cas d'Usage

### ğŸ“š Ã‰ducation
- Apprentissage interactif des algorithmes ML
- Visualisation des concepts abstraits
- ExpÃ©rimentation avec diffÃ©rents paramÃ¨tres

### ğŸ”¬ Recherche
- Prototypage rapide d'algorithmes
- Comparaison de performances
- GÃ©nÃ©ration de datasets synthÃ©tiques

### ğŸ’¼ Professionnel
- DÃ©monstration de concepts ML
- SÃ©lection d'algorithmes appropriÃ©s
- Analyse exploratoire de donnÃ©es

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voici comment contribuer :

1. **Fork** le projet
2. **CrÃ©ez** votre branche (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrez** une Pull Request

### Guidelines
- Suivre le style de code existant
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation
- Commenter le code complexe

## ğŸ“ Roadmap

- [ ] Ajout de nouveaux algorithmes (SVM, Random Forest, DBSCAN)
- [ ] Support des datasets personnalisÃ©s (upload CSV)
- [ ] Export des rÃ©sultats et visualisations
- [ ] Mode comparaison avancÃ©e avec cross-validation
- [ ] API REST pour l'accÃ¨s programmatique
- [ ] Tutoriels interactifs intÃ©grÃ©s
- [ ] Support multilingue
- [ ] Mode sombre

## ğŸ› Bugs Connus

- Performance dÃ©gradÃ©e avec CAH pour n > 500 Ã©chantillons
- Pas de support pour donnÃ©es >2D dans les visualisations

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¨â€ğŸ’» Auteur

**Votre Nom**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Votre Profil](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

## ğŸ™ Remerciements

- Merci Ã  la communautÃ© Streamlit pour l'excellent framework
- Inspiration tirÃ©e des cours de Machine Learning de Stanford
- Datasets synthÃ©tiques gÃ©nÃ©rÃ©s avec Scikit-learn

## ğŸ“š Ressources Additionnelles

- [Documentation Streamlit](https://docs.streamlit.io/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Pattern Recognition and Machine Learning - Bishop](https://www.springer.com/gp/book/9780387310732)
- [The Elements of Statistical Learning - Hastie et al.](https://web.stanford.edu/~hastie/ElemStatLearn/)

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/ml-interactive-dashboard&type=Date)](https://star-history.com/#yourusername/ml-interactive-dashboard&Date)

---

<div align="center">
    <p>Fait avec â¤ï¸ et â˜•</p>
    <p>Si ce projet vous a aidÃ©, n'oubliez pas de lui donner une â­</p>
</div>